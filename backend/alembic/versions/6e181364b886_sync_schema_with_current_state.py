"""sync_schema_with_current_state

Revision ID: 6e181364b886
Revises: ef3bb807b7d5
Create Date: 2026-01-19 01:19:54.423560

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '6e181364b886'
down_revision: Union[str, None] = 'ef3bb807b7d5'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Safely drop business_time_settings table only if it exists and is empty
    connection = op.get_bind()
    
    # Check if table exists first
    table_exists = connection.execute(sa.text(
        """
        SELECT EXISTS (
            SELECT FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_name = 'business_time_settings'
        )
        """
    )).scalar()
    
    if table_exists:
        result = connection.execute(sa.text("SELECT COUNT(*) FROM business_time_settings"))
        row_count = result.scalar()
        
        if row_count == 0:
            print("Dropping empty business_time_settings table")
            op.drop_table('business_time_settings')
        else:
            print(f"Skipping drop of business_time_settings table - contains {row_count} rows")
    else:
        print("business_time_settings table does not exist, skipping drop")
    
    # Update timestamp columns to use timezone-aware DateTime
    op.alter_column('departments', 'deleted_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('layby_config', 'deleted_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('laybys', 'deleted_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    
    # Add indexes for stock_reservations table (if table and indexes don't exist)
    # First check if the table exists
    stock_reservations_exists = connection.execute(sa.text(
        """
        SELECT EXISTS (
            SELECT FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_name = 'stock_reservations'
        )
        """
    )).scalar()
    
    if stock_reservations_exists:
        # Check and create indexes using raw SQL with IF NOT EXISTS
        indexes_to_create = [
            ('ix_stock_reservations_layby_id', 'stock_reservations', 'layby_id'),
            ('ix_stock_reservations_location_id', 'stock_reservations', 'location_id'),
            ('ix_stock_reservations_product_id', 'stock_reservations', 'product_id'),
            ('ix_stock_reservations_status', 'stock_reservations', 'status'),
        ]
        
        for index_name, table_name, column_name in indexes_to_create:
            # Check if index exists
            index_exists = connection.execute(sa.text(
                f"""
                SELECT EXISTS (
                    SELECT 1 FROM pg_indexes 
                    WHERE schemaname = 'public' 
                    AND tablename = '{table_name}' 
                    AND indexname = '{index_name}'
                )
                """
            )).scalar()
            
            if not index_exists:
                print(f"Creating index {index_name}")
                connection.execute(sa.text(
                    f"CREATE INDEX {index_name} ON {table_name} ({column_name})"
                ))
            else:
                print(f"Index {index_name} already exists, skipping")
    else:
        print("stock_reservations table does not exist yet, skipping index creation")
    
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    # Only drop indexes if the table exists
    connection = op.get_bind()
    stock_reservations_exists = connection.execute(sa.text(
        """
        SELECT EXISTS (
            SELECT FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_name = 'stock_reservations'
        )
        """
    )).scalar()
    
    if stock_reservations_exists:
        op.drop_index(op.f('ix_stock_reservations_status'), table_name='stock_reservations')
        op.drop_index(op.f('ix_stock_reservations_product_id'), table_name='stock_reservations')
        op.drop_index(op.f('ix_stock_reservations_location_id'), table_name='stock_reservations')
        op.drop_index(op.f('ix_stock_reservations_layby_id'), table_name='stock_reservations')
    op.alter_column('laybys', 'deleted_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('layby_config', 'deleted_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('departments', 'deleted_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.create_table('business_time_settings',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('business_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('day_end_time', postgresql.TIME(), server_default=sa.text("'23:59:00'::time without time zone"), autoincrement=False, nullable=False),
    sa.Column('auto_clock_out_penalty_hours', sa.NUMERIC(precision=4, scale=2), server_default=sa.text('5.00'), autoincrement=False, nullable=True),
    sa.Column('standard_work_hours', sa.NUMERIC(precision=4, scale=2), server_default=sa.text('8.00'), autoincrement=False, nullable=True),
    sa.Column('overtime_threshold', sa.NUMERIC(precision=4, scale=2), server_default=sa.text('8.00'), autoincrement=False, nullable=True),
    sa.Column('payroll_period_type', sa.VARCHAR(length=20), server_default=sa.text("'monthly'::character varying"), autoincrement=False, nullable=True),
    sa.Column('payroll_period_start_day', sa.INTEGER(), server_default=sa.text('1'), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('deleted_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['business_id'], ['businesses.id'], name=op.f('business_time_settings_business_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('business_time_settings_pkey')),
    sa.UniqueConstraint('business_id', name=op.f('business_time_settings_business_id_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    # ### end Alembic commands ###
